---
title: GCP 기반 AI/ML 핵심 기술 공부하기
description: 부트캠프 수강 기록
author: annmunju
date: 2025-06-17 17:50:00 +0900
categories: [기술 공부 기록, AI]
tags: [ml, ai, bigquary, gcp, vertex-ai, mlops]
pin: false
math: true
mermaid: false
comments: false
---

> 구글 클라우드 기반 AI, ML 부트캠프 수강 기록

구글 클라우드에서 제공하는 서비스들 전체를 살펴보고 이를 실습하는 부트캠프를 수강했습니다. 다음은 수강 기록을 정리한 내용이이다.

## 1. Google Cloud 에서 AI/ML 쓰려면 필요한것

![전체 요약](sources/tech1_tech-deep-dives/2025-06-17-google-ml/1.png)

| 계층        | 구성 요소 및 특징                                               |
|-------------|------------------------------------------------------------------|
| **인프라 계층** | 컴퓨팅(Compute Engine, GKE), 스토리지(Cloud Storage, BigQuery)  |
| **데이터 계층** | 데이터 분석 및 전처리 도구: BigQuery, Dataflow 등               |
| **AI 계층**   | Vertex AI (AutoML, Pipelines, Model Garden, Studio 등)          |

> 즉 컴퓨팅 자원과 스토리지 + AI가 별도로 이뤄져 있어 구분해서 사용한다!

### 인프라 계층 (컴퓨팅)

| 서비스           | 설명                                | 사용 시점                       |
|------------------|-------------------------------------|----------------------------------|
| **Compute Engine**   | IaaS, VM 직접 제어                  | 커스텀 모델 학습 환경 구축 시   |
| GKE              | Kubernetes 기반 컨테이너 오케스트레이션 | MLOps 자동화, 파이프라인 운영 |
| Cloud Run        | 컨테이너 기반 서버리스 실행 환경    | 경량 모델 API 서빙 시           |
| Cloud Functions  | 이벤트 기반 FaaS                    | 예: S3 업로드 트리거 시 예측   |
| TPU              | Google 전용 ML 가속 칩              | 고성능 딥러닝 학습 시            |

### 데이터 계층 (스토리지)

| 데이터 유형              | 스토리지 옵션        | 특징                                   |
|---------------------------|-----------------------|------------------------------------------|
| 비정형 데이터 (이미지 등)  | Cloud Storage         | 핫/콜드/아카이브 계층 제공               |
| 트랜잭션 + SQL 기반       | Cloud SQL, Spanner    | SQL 기반, Spanner는 글로벌 확장 가능    |
| NoSQL 실시간 처리         | Firestore, Bigtable   | 스키마 유연, 낮은 지연시간               |
| 분석/ML 용                | **BigQuery**              | SQL 기반 대규모 분석 + ML 모델 통합     |


위는 GCP에서 제공하는 각각의 **컴퓨팅과 스토리지 서비스**이다. 특징을 고려해 필요한 지원을 사용한다. 다음은은 AI 계층에 사용되는 **Vertex AI**이다.

---

## 2. Vertex AI 소개
엔드투엔드 AI 개발을 위한 Google Cloud의 대표 플랫폼이다.

- **Vertex AI Workbench**: Jupyter 기반 노트북 환경  
- **Vertex AI Pipelines**: Kubeflow 기반 MLOps 자동화  
- **Vertex AI Training**: 커스텀 모델 학습 환경  
- **Vertex AI Prediction**: 실시간/배치 모델 서빙  
- **Vertex AI Vizier**: 하이퍼파라미터 자동 탐색  
- **Vertex AI Studio / Model Garden**: 프롬프트 설계 및 사전학습 생성형 모델 활용  

보통 실무에서는 **BigQuery ML로 빠르게 시작**하고, **Vertex AI로 확장하며 운영 관리**하는데 이용한다.
Vertex AI에 대해서는 MLOps와 함께 더 자세하게 후술!

---

## 3. 실무 적용 BigQuery ML

우선 그 전에 실무에서 자주 사용하는 빅쿼리에 대해서 알아보자. 
SQL만으로 머신러닝 **모델을 만들고 학습하며 예측**까지 가능하다.

- 지원 모델  
    - logistic_reg, linear_reg, kmeans, arima_plus, xgboost, dnn_classifier, dnn_regressor, matrix_factorization  
- 예시 SQL 문  
```sql
CREATE MODEL ... OPTIONS(model_type='logistic_reg', input_label_cols=...) AS SELECT ...  
SELECT * FROM ML.EVALUATE(...)  
SELECT * FROM ML.PREDICT(...)  
```
- 전처리 자동 지원 (예: 원-핫 인코딩 처리)

그러니 SQL만 알면 누구나 빠르게 **ML 프로토타입을 실현**해볼 수 있다. 구체적인 커스텀 모델을 훈련하고 사용하는 전반의 과정이 필요한 경우 Vertex AI를 이용하는 것이 좋다. 

---

## 4. MLOps와 Vertex AI Pipelines 이해

**MLOps란 데이터를 수집하는 것 부터 모델을 훈련하고 운영하는 것을 지원하는 전반의 과정**을 이르는 표현이다. 
이에 구글 클라우드는 다음과 같은 서비스를 제공하고 있다.

- **Vertex AI Pipelines**: 파이프라인 구성 및 재사용  
    - 파이프라인 정의 방식  
        - Python 기반 DSL (Kubeflow Pipelines SDK) 사용  
        - 컴포넌트 단위로 분리하여 재사용 가능  
        - 예: 데이터 전처리 → 모델 학습 → 배포까지 일련의 프로세스 자동화
- 실행 추적 및 재현성 보장  
    - 각 컴포넌트 실행 결과 저장  
    - 실험 버전 비교 및 리롤백 가능  
    - ML Metadata 관리 자동화
    - **Model Registry**: 모델 버전 관리  
    - **Monitoring**: 성능 저하, 데이터 드리프트 감지  
    - **Explainable AI**: 모델 예측 근거 분석  
- GKE, Vertex AI Training, Dataflow 등 다양한 백엔드와 연동 가능

즉, Vertex AI Pipelines는 머신러닝 전체 주기를 코드 기반으로 통합하고 자동화하는 MLOps 도구다. 마지막으로 모델의 개발과 운영의 실제 워크플로를 요약해 어떤 서비스를 제공하고 있는지 순서대로 설명한다.

---

## 5. 모델 개발부터 운영까지의 실제 워크플로 요약

![전체 요약](sources/tech1_tech-deep-dives/2025-06-17-google-ml/2.png)

### a. 머신러닝 워크플로 구조 (Vertex AI 기준)

- 단계 구성  
  1) 데이터 준비  
  2) 데이터 전처리 및 탐색  
  3) 모델 학습  
  4) 하이퍼파라미터 튜닝  
  5) 모델 평가  
  6) 모델 배포 및 예측  
  7) 모니터링 및 재학습

Vertex AI는 위 모든 과정을 **한 플랫폼 내에서 수행** 가능하며 각각의 단계를 별도 서비스로 나누지 않고 **통합된 워크플로로 운영**한다.

### b. 데이터 준비 및 탐색

- **데이터 소스** : Cloud Storage, BigQuery, Cloud SQL, Vertex Dataset 등 다양한 연동 가능 
    - BQML 또는 Dataflow를 통한 전처리 가능
- **탐색 분석** : Vertex AI Workbench에서 pandas, seaborn 등 사용 가능  
    - 시각화를 통한 이상값 탐지 및 특성 추출 가능

위와 같은 서비스를 이용하면 데이터 준비 단계부터 GCP와 통합된 환경으로 제공할 수 있습니다.

### c. Vertex AI Training

- 커스텀 학습: Python 코드 + Docker 컨테이너 기반 실행  
- AutoML 학습: 코드 없이 GUI 기반  
- 분산 학습, GPU/TPU 자원 선택 가능

- 학습 아티팩트: 모델, 로그, 메타데이터 자동 저장  
    - Cloud Logging, Cloud Storage, AI Metadata 연동

사전 설정만 하면 **학습 → 평가 → 저장까지 전자동으로 처리**할 수 있다.

### d. 하이퍼파라미터 튜닝 (Vertex AI Vizier)

- **튜닝 전략** : Grid Search, Random Search, Bayesian Optimization 등 지원  
    - Metric 기준 자동 최적화
- **실행 방식** : TrainingJob 내에서 tuningJob으로 분기  
    - 실험 결과 기록, 시각화 지원

성능 향상을 위한 하이퍼파라미터 탐색을 자동화하여 반복 비용을 절감할 수 있다.

### e. 모델 배포 및 예측

- **모델 등록 및 버전 관리** : Vertex AI Model Registry에 등록  
    - 동일 모델의 다양한 버전 비교 가능
- **Endpoint 생성 후 실시간 예측**
    - Online prediction: REST 호출 기반  
    - Batch prediction: 대량 예측용, CSV 또는 BigQuery 입력 가능
- **A/B 테스트 지원** : 여러 모델 버전 간 트래픽 분할 가능  
    - 모니터링 지표 기반으로 자동 전환 가능

이와 같이 모델의 배포부터 운영, 트래픽 조절까지 전체 라이프사이클을 관리할 수 있다.

### f. 모델 모니터링 및 재학습

- **예측 품질 모니터링** : 입력 특성의 drift, skew 자동 감지. 예측 정확도 감소 추적
- **알림 및 리트리거** : 조건 충족 시 자동 재학습 트리거 가능 (Vertex AI Pipelines + Scheduler)
- **Cloud Monitoring 연동** : 메트릭 시각화, 경보 설정 가능

이어진 모니터링을 통해 운영 단계에서 품질을 지속적으로 유지하고 개선한다.

---

## 마무리 및 결론

이번 부트캠프를 통해 GCP 상에서 제공하는 AI/ML 생태계를 계층적으로 이해하고 **실무에 필요한 자동화 도구(Vertex AI Pipelines), 빠른 프로토타이핑(BigQuery ML)까지 전반적인 흐름**을 파악할 수 있었다.

특히 다음과 같은 점들이 인상 깊었다.
- 데이터 준비부터 모델 서빙까지 통합된 Vertex AI 파이프라인 구성
- MLOps 운영을 위한 자동화 기능, 실험 추적 및 버전 관리
- 다양한 학습 방식(BigQuery ML, AutoML, Custom Training)의 조합 전략

(블로그 내용으로는 포함하지 않았지만) 실습 과정을 포함하고 있는 수업이어서 더욱 빠르게 이해할 수 있는 수업이었다. 끝!
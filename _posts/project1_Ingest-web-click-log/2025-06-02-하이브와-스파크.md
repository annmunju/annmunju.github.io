---
title: 빅데이터 전처리를 위한 기술 배우기
description: 하둡, 하이브와 스파크
author: annmunju
date: 2025-06-02 15:32:00 +0900
categories: [Ingest-web-click-log, study]
tags: [hadoop, hive, spark]
pin: false
math: true
mermaid: true
comments: true
---

> 대용량 데이터를 처리하기 위한 여러 도구

이제껏 경험해본 데이터 전처리 프레임워크는 pandas 뿐이었습니다. 데이터 엔지니어가 데이터를 처리할 때는 주로 빅데이터를 분산 저장, 처리하는 도구인 hadoop, spark를 처음부터 제대로 이해하기 위해서 먼저 개념을 익히고자 합니다.

## 들어가며 : 오늘의 목표

1. 하둡이 뭔지 이해하기 -> 그리고 하이브도 같이 이해하기
2. 스파크가 뭔지 이해하기
3. 이를 기반으로 전체적인 다음 단계 설계하기

---

## 1. Hadoop과 Hive 이해  

### 1.1. Hadoop

아파치 하둡은 대용량 데이터를 분산 저장, 처리하기 위한 오픈소스 프레임워크입니다. 단일 서버가 감당하기 어려운 데이터를 저가형 서버==노드에 나눠 저장하고 MapReduce 같은 분산 알고리즘을 통해 병렬 처리할 수 있도록 설계되었습니다.

- 구성 요소
    - **하둡 파일시스템 (HDFS)**: 블록 단위로 나눠 여러 노드에 복제하여 저장할 수 있는 분산 파일 시스템
    - **YARN (Yet Another Resource Negotiator)**: 클러스터 전체 자원(CPU, 메모리 등)을 관리하고 작업(Job)을 배정·스케줄링하는 Resource Manager 역할
    - **MapReduce 모델**: 하둡이 처음 나왔을 때 배치 처리의 표준으로 자리 잡은 분산 프로그래밍 모델. Map 단계에서 키-값으로 변환해 분산처리하고 reduce 단게에서 map 단계 결과를 모아 최종 집계, 처리함.

>  
- HDFS는 데이터를 작은 블록으로 나눠 여러 곳에 복제해서 저장 → 노드 장애 시 데이터 유실을 방지  
- 병렬 읽기/쓰기로 대용량 파일을 빠르게 처리  
- NameNode(메타데이터)와 DataNode(실제 저장)로 역할이 분리되어 있음  
{: .prompt-tip}

### 1.2. Hive

Apache Hive는 HDFS에 저장된 대용량 데이터를 SQL처럼 간단하게 조회·분석할 수 있게 해 주는 데이터웨어하우스 도구입니다. 내부적으로 HiveQL 쿼리를 MapReduce/Tez/Spark 작업으로 변환해 분산 처리합니다.

- **Hive 메타스토어와 테이블 구조:**  
    - 메타스토어는 테이블 이름·컬럼 정보·파티션 정보·파일 위치(HDFS 경로) 같은 메타데이터를 RDBMS에 저장  
    - EXTERNAL 테이블과 MANAGED 테이블 두 가지 종류가 있으며, 파티션을 활용해 데이터 디렉터리를 나누어 저장  
- **HiveQL로 데이터 조회하기:**  
    - SQL과 거의 동일한 문법인 HiveQL을 사용  
    - 단일 쿼리를 내부적으로 분산 작업(MapReduce/Tez/Spark)으로 변환하여 실행  
    - 테이블 생성, 파티션 관리, SELECT·GROUP BY·JOIN 등 기본 SQL 기능 지원  
- **Hive와 Hadoop의 연동 방식:**  
    - HiveServer2가 메타스토어에서 HDFS 저장 위치를 조회  
    - 실행 엔진(MapReduce/Tez/Spark)이 HDFS 파일을 분산 읽어 처리  
    - 결과를 임시 HDFS에 저장한 뒤 HiveServer2가 클라이언트에 반환  

>
- Hive 메타스토어는 테이블 스키마→HDFS 경로를 관리 → SQL 쿼리를 분산 작업으로 변환  
- 파티셔닝을 사용하면 특정 디렉터리만 읽어 쿼리 성능을 높일 수 있음  
- HiveQL 엔진(MapReduce vs. Tez vs. Spark)을 변경해 성능 최적화 가능 
{: .prompt-tip}

---

### 1.3. Hadoop / Hive 사용 사례와 장단점

#### 사용 사례

| 사용 사례             | 설명                                                     |
| ------------------ | ------------------------------------------------------ |
| 로그 데이터 배치 분석    | 하루치 클릭스트림·서버 로그 등 대량 파일을 MapReduce나 HiveQL로 집계          |
| 데이터웨어하우스 구축    | HDFS에 저장된 데이터를 Hive 테이블로 정의해 BI 도구에서 SQL로 대화형 조회         |
| 대규모 ETL           | 여러 소스(MySQL, CSV, 로그 등) → HDFS 적재 → MapReduce/HiveQL로 변환·적재    |
| 배치 머신러닝 전처리    | HDFS 원본 데이터를 MapReduce로 피처 생성 → Hive 테이블로 저장 → Spark ML 학습 |

#### 장단점

| 구분    | 장점                                                                    | 단점                                                                        |
| ----- | ----------------------------------------------------------------------- | -------------------------------------------------------------------------- |
| Hadoop | - 노드를 추가하면 용량·연산 능력 확장 가능<br>- 블록 복제로 내결함성 확보<br>- 오픈소스 에코시스템 연동 용이 | - 디스크 기반 처리로 반복 연산 시 속도 느림<br>- 실시간 분석 부적합<br>- 여러 서비스 운영 부담        |
| Hive   | - SQL 친화적으로 대용량 데이터 처리<br>- 파티셔닝으로 쿼리 성능 개선<br>- HiveQL→MapReduce/Tez/Spark 자동 변환 | - 기본 MapReduce 엔진 사용 시 실행 지연<br>- 복잡한 UDF 개발 필요 시 진입 장벽 상승<br>- 실시간 처리 불가 |

이처럼 Hadoop은 대용량 데이터를 안정적으로 분산 저장·처리하는 기반을 제공하고 Hive는 그 위에서 SQL처럼 손쉽게 데이터를 조회·분석할 수 있게 해주는 도구입니다.  

---

## 2. Spark

필요한 데이터를 메모리에 올려두고 계산하여 읽고 쓰기를 빠르게 처리할 수 있는 엔진입니다. 

### 2.1. Spark 개요  

스파크는 다음과 같은 특징이 있습니다.
- 필요한 데이터를 메모리(컴퓨터 RAM)에 올려두고 계산하니까 하둡처럼 디스크에서 계속 읽고 쓰는 것보다 **훨씬 빨라요**.
- 배치 작업도 물론 할 수 있지만, **실시간에 새로운 데이터가 들어오면 바로바로 처리해서 결과를 보여줄 수 있는 기능**(Structured Streaming)이 있어요.
    - 클릭 이벤트가 Kafka 같은 메시지 큐에 들어오자마자 현재 시점까지의 집계값을 끊임없이 갱신해 대시보드에 바로 띄울 수 있어요.
- 이외에도 다양한 분석/응용 기능이 있어요.
    - SQL처럼 테이블 형태로 데이터를 다룰 수 있는 **Spark SQL**
    - 머신러닝 알고리즘을 쉽게 사용하게 해주는 **MLlib**
    - 그래프 알고리즘을 지원하는 **GraphX** 등
    - 이 모든 기능을 하나의 통합된 환경에서 거의 동일한 코드 스타일(PySpark, Scala, R 등)로 쓸 수 있어요.

---

### 2.2. Spark 아키텍처

1. **Driver와 Executor 구조**  
   - **Driver**는 Spark 애플리케이션의 중심 역할을 해요.  
     - 프로그램의 메인 메서드를 실행하면서, 작업을 여러 개의 태스크(Task)로 나누고 전체 실행 계획(DAG)을 생성합니다.  
     - 실행 계획을 클러스터 매니저에게 전달해 자원을 요청하고, 할당된 Executor에게 작업을 분배합니다.  
     - 작업 진행 상황을 모니터링하고, 최종 결과를 모아 사용자가 원하는 형태로 돌려줍니다.  
   - **Executor**는 실제 데이터를 계산하는 워커 입니다.  
     - 클러스터 매니저가 할당한 노드(NodeManager)에 JVM 프로세스로 올라가며, Driver가 준 Task를 병렬로 실행해요.  
     - 입력 데이터를 읽어서 각 Task별로 연산(맵, 필터, 집계 등)을 수행하고, 결과를 메모리(혹은 디스크)에 저장합니다.  
     - 작업이 끝나면 Driver에게 결과나 중간 상태를 보고하고, 필요 시 셔플(shuffle) 과정을 통해 다른 Executor와 데이터를 주고받습니다.

2. **클러스터 매니저(YARN 모드) 연동**  
   - Spark는 여러 종류의 클러스터 매니저를 지원하지만, Hadoop 환경에서는 **YARN**을 많이 사용합니다.  
   - **Spark on YARN** 동작 흐름:  
     1. 사용자가 `spark-submit --master yarn` 명령으로 애플리케이션을 제출  
     2. YARN ResourceManager(RM)는 새로운 **ApplicationMaster(AM)** 컨테이너를 실행하여 Driver 프로세스를 시작  
     3. AM(Driver)은 RM에게 Executor 몇 개, CPU 몇 개, 메모리 몇 GB를 할당해 달라는 요청을 보냄  
     4. RM이 각 NodeManager(NM)에게 자원 할당을 지시 → Executor 컨테이너가 노드별로 실행  
     5. Driver는 할당된 Executor에 Task를 분배하여 병렬 처리 수행  
     6. 작업 완료 후 AM이 RM에 작업 종료를 알리고, RM이 할당된 자원을 회수  

>
- **Driver**는 애플리케이션의 실행 계획(DAG) 작성과 Task 분배를 담당하는 뇌 역할  
- **Executor**는 Driver가 분배한 Task를 실제로 메모리 기반으로 실행하는 일꾼 역할  
- **Spark on YARN** 모드에서는 ResourceManager가 ApplicationMaster(Driver)를 띄우고, NodeManager가 Executor 컨테이너를 실행  
- YARN이 전체 클러스터 자원을 관리해주므로, Spark 작업과 다른 Hadoop 작업이 충돌 없이 함께 실행될 수 있음  
- 노드를 추가하면 더 많은 Executor를 할당받아 병렬 처리 성능을 쉽게 확장할 수 있음  
{: .prompt-tip}

---

### 2.3. Spark vs. Hadoop 비교

| 비교 항목                  | Hadoop (MapReduce)                                                                 | Spark                                                                                              |
| ----------------------- | -------------------------------------------------------------------------------- | -------------------------------------------------------------------------------------------------- |
| **처리 속도 및 메모리 활용**   | - 디스크 기반 처리 → 각 단계마다 디스크 읽기/쓰기 발생<br>- 메모리 캐싱 불가 → 반복 연산 시 속도 느림      | - 메모리 기반 처리 → 데이터를 메모리에 올려두고 연산<br>- 반복 연산 시 추가 디스크 I/O 없이 빠른 처리 가능 |
| **배치 방식 vs. 스트리밍 방식** | - 순수 배치 전용 모델<br>- 하루치 데이터를 몰아서 처리에만 적합<br>- 실시간 스트리밍 처리 불가             | - 배치와 스트리밍(Structured Streaming) 모두 지원<br>- 실시간으로 들어오는 데이터 거의 실시간 처리 가능      |
| **데이터웨어하우스 연동 관점**   | - Hive, HBase 등 Hadoop 에코시스템과 연동<br>- HiveQL→MapReduce로 대용량 배치 쿼리 가능                   | - Spark SQL을 통해 Hive 메타스토어 테이블 바로 조회 가능<br>- Parquet/ORC 등 컬럼 형식 파일을 직접 읽고 쓰기 용이 |

---

## 3. 전체적인 다음 단계 설계

아래 다이어그램은 EC2 기반으로 Airflow → Spark → Hive/Hadoop → HDFS DataNode 순서로 데이터 파이프라인을 구성한 예시입니다. 각 구성 요소의 역할과 실행 흐름을 단계별로 설명합니다.

![파이프라인 다이어그램](sources/project1_Ingest-web-click-log/2025-06-02-하이브와-스파크.png)

### 3.1. EC2-Airflow

- **역할**  
  - Airflow 가 설치된 EC2 인스턴스로 매일 밤 00:00(서울 시간)에 설정된 DAG가 자동으로 실행되도록 스케줄링을 담당합니다.
  
- **주요 동작 흐름** 
  1. Airflow 스케줄러가 예약된 시간(UTC 15:00, KST 00:00)에 DAG를 트리거  
  2. DAG 내의 Operator가 필요한 명령을 호출  
  3. Spark 작업을 수행할 Spark Cluster로 배치 job 요청  
  4. 실행 결과를 모니터링하고, 오류 발생 시 알림 처리(이메일/슬랙 등)

### 3.2. Spark Cluster

- **구성**  
  - EC2 인스턴스 중 Spark Client(혹은 Spark Master 역할)를 별도 운영하고,  
  - 실제 계산은 Hadoop 클러스터의 DataNode 위에서 실행되는 Spark Executor가 수행합니다.
  - 모드: **Spark on YARN**  
    - Spark Driver와 Aux 애플리케이션(AM)은 YARN ResourceManager에 의해 컨테이너로 실행되고,  
    - Executor는 YARN NodeManager 컨테이너로 올라가서 병렬 계산을 수행합니다.

- **주요 동작 흐름**  
  1. Airflow가 Spark Driver를 YARN ResourceManager에 제출  
  2. YARN RM이 Spark Driver를 위한 컨테이너 `ApplicationMaster` 를 할당  
  3. Driver(ApplicationMaster)가 Executor N개, CPU X개, 메모리 YGB 등의 자원을 YARN RM에 요구  
  4. YARN RM이 NodeManager 위에 Executor 컨테이너를 할당하고,  
  5. 각 Executor가 HDFS에 저장된 JSON을 읽어 분석—데이터 정제, 스키마 변환, 파티셔닝 등 수행  
  6. 분석된 결과를 Parquet/ORC 포맷으로 HDFS Hive Warehouse 디렉터리에 저장  
  7. Driver가 모든 Executor의 작업 완료를 확인하고, 성공/실패 상태를 Airflow로 반환  

### 3.3. EC2-Hive/Hadoop

- **역할**  
  - Hadoop NameNode + YARN ResourceManager가 실행되는 마스터 노드로 **Hive Metastore**와 **HiveServer2**도 동시에 띄워서 Hive 테이블 메타데이터와 SQL 인터페이스를 관리합니다.
  - HDFS 위에 `/user/hive/warehouse/…` 디렉터리를 생성·소유하고, Spark이 쓴 Parquet/ORC 파일을 Hive 테이블 형식으로 유지합니다.

- **주요 구성 요소**  
  1. **HDFS NameNode**  
     - HDFS 전체 파일블록 메타데이터를 관리(어떤 DataNode에 어느 블록이 저장되었는지)  
  2. **YARN ResourceManager**  
     - Spark(및 향후 다른 YARN 애플리케이션)의 자원을 통합 배분  
  3. **Hive Metastore**  
     - 테이블 스키마, 파티션 정보, HDFS 디렉터리 매핑 정보를 RDB(MySQL 등)에 저장  
  4. **HiveServer2**  
     - 외부 BI/SQL 클라이언트(JDBC/ODBC 등)가 접속해 HiveQL 쿼리를 실행할 수 있는 Thrift 인터페이스

### 3.4. HDFS DataNodes (Spark Executors)

- **역할**  
  - Hadoop DataNode와 YARN NodeManager 역할을 하는 EC2 워커 노드로
  - Spark Executor가 올라가서 분산 계산을 수행하고 HDFS 블록을 로컬 디스크에 저장하거나 읽습니다.

- **설치 항목**  
  1. **Hadoop DataNode**  
     - HDFS 블록을 저장하고, NameNode와 주기적으로 핑(heartbeat)으로 상태를 공유  
  2. **YARN NodeManager**  
     - ResourceManager가 할당한 컨테이너(Executor) 실행 및 자원(메모리/CPU) 관리  
  3. **Spark Executor**  
     - Driver로부터 전달된 Task를 병렬 실행  
     - 입력 데이터를 HDFS에서 로컬 메모리로 읽어와 in-memory 연산  
     - 계산 결과(Parquet/ORC 파일)를 다시 HDFS에 저장

- **데이터 흐름 예시**  
  1. Spark Driver의 지시에 따라, Executor들이 HDFS DataNode 로컬 디렉터리에서 JSON 파일을 읽음  
  2. 메모리에 데이터를 캐시하여 반복 연산을 수행하거나, 바로 변환하고 집계  
  3. 최종 결과를 Hive Warehouse 경로에 Parquet/ORC 포맷으로 저장 → Hive Metastore로 파티션 추가  
  4. 결과 조회 시 HiveServer2를 통해 외부 쿼리 또는 BI 툴에 응답

---

### 3.5. 요약

- **Airflow EC2**  
  - Daily 00:00에 필요한 명령으로 Spark 애플리케이션을 제출 → Spark Cluster에 배치 Job 요청  

- **Spark Cluster (Spark on YARN)**  
  - YARN ResourceManager가 Driver(AM)을 실행 → Driver가 Executor 컨테이너 요청 → NodeManager에서 Executor 실행  
  - Executor들이 HDFS DataNode에서 JSON을 읽어 분석 → Parquet/ORC 결과를 HDFS Hive Warehouse에 저장  

- **EC2-Hive/Hadoop**  
  - Hive Metastore가 HDFS 테이블·파티션 메타데이터를 관리 → HiveServer2를 통해 SQL/BI 쿼리 제공  
  - HDFS NameNode와 YARN RM이 전체 클러스터 자원·파일 저장소를 통합 관리  

- **HDFS DataNodes**  
  - Spark Executor가 올라가 실제 계산을 수행하고, 로컬에 블록을 캐시하여 병렬 연산  
  - 계산된 결과 파일을 HDFS에 저장 → Hive 테이블과 연동되어 조회·분석용 데이터웨어하우스로 활용  

이 설계를 통해 Airflow가 스케줄링 → Spark on YARN이 분산 실행 → Hive/Hadoop이 저장·메타데이터 관리 → HDFS DataNode가 실제 연산으로 이어지는 전체 파이프라인을 한눈에 파악할 수 있습니다.  
이후는 이 파이프라인을 구체화하고 실제로 구성하는 과정을 진행하면서 정리해보려고 합니다. 파이팅!
---
title: ì›¹ í´ë¦­ìŠ¤íŠ¸ë¦¼ ìˆ˜ì§‘í•˜ê¸° 4) EC2 ì¹´í”„ì¹´ & ì»¨í…Œì´ë„ˆ Lambda ë°°í¬
description: ì¹´í”„ì¹´ë¥¼ í”„ë¼ì´ë¹—ìœ¼ë¡œ ì „í™˜í•˜ê³  Lambdaë¡œ í”„ë¡œë“€ì„œ ë¶™ì´ê¸°
author: annmunju
date: 2025-05-29 11:54:00 +0900
categories: [Ingest-web-click-log, poc]
tags: [kafka, lambda, s3]
pin: false
math: true
mermaid: true
comments: true
---

> ì´ì œ í´ë¼ìš°ë“œ í™˜ê²½ì—ì„œ ëŒë‹¤ë¡œ ë°ì´í„° ìˆ˜ì§‘ ë³¸ê²©í™”

ì´ë²ˆ ì£¼ì—ëŠ” EC2ì— ë„ìš´ Kafka í´ëŸ¬ìŠ¤í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ GitHub Pagesì— í˜¸ìŠ¤íŒ…ëœ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ë°œìƒí•˜ëŠ” í´ë¦­ìŠ¤íŠ¸ë¦¼ ë¡œê·¸ë¥¼ AWS Lambdaë¡œ ìˆ˜ì§‘í•˜ëŠ” í”„ë¡œì„¸ìŠ¤ë¥¼ ì™„ì„±í•  ê³„íšì…ë‹ˆë‹¤.  
Lambda í”„ë¡œë“€ì„œ í•¨ìˆ˜ê°€ Kafka í† í”½ì— ë©”ì‹œì§€ë¥¼ ì „ì†¡í•˜ë©´, ë™ì¼í•œ EC2ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ Kafka Connect S3 Sink ì»¤ë„¥í„°ê°€ í•´ë‹¹ í† í”½ì„ ì†Œë¹„í•´ S3ì— ë°°ì¹˜ ì ì¬í•˜ëŠ” end-to-end íŒŒì´í”„ë¼ì¸ì„ êµ¬ì¶•í•´ë´…ë‹ˆë‹¤.  

---

## ì•„í‚¤í…ì²˜ ê·¸ë¦¬ê¸°

![ë‹¨ì¼ í´ëŸ¬ìŠ¤í„° ì•„í‚¤í…ì²˜](sources/project1_Ingest-web-click-log/2025-05-28-ëŒë‹¤-S3-ì €ì¥/01.png)

1. **í´ë¼ì´ì–¸íŠ¸ â†’ API Gateway**
    - GitHub Pages(Jekyll)ë¡œ í˜¸ìŠ¤íŒ…ëœ í”„ë¡ íŠ¸ì—”ë“œì—ì„œ JS í´ë¦­ìŠ¤íŠ¸ë¦¼ ì´ë²¤íŠ¸ê°€ ë°œìƒí•˜ë©´ í¼ë¸”ë¦­ API Gateway ì—”ë“œí¬ì¸íŠ¸ë¡œ HTTP í˜¸ì¶œì´ ë“¤ì–´ì˜µë‹ˆë‹¤.
    - API GatewayëŠ” Lambda Kafka Producer í•¨ìˆ˜ë¥¼ íŠ¸ë¦¬ê±°í•©ë‹ˆë‹¤.
2. **Lambda Producer**
    - í•¨ìˆ˜ ì½”ë“œê°€ Kafka í´ëŸ¬ìŠ¤í„°ì˜ í† í”½(clickstream)ì— ë©”ì‹œì§€ë¥¼ í”„ë¡œë“€ì‹±í•©ë‹ˆë‹¤.
3. **EC2 Kafka í´ëŸ¬ìŠ¤í„°**
    - EC2 ì¸ìŠ¤í„´ìŠ¤ ìœ„ì—ì„œ Zookeeper + Kafka Brokerê°€ í•¨ê»˜ ë™ì‘í•©ë‹ˆë‹¤.
    - ì´ í´ëŸ¬ìŠ¤í„°ê°€ í”„ë¡œë“€ì„œê°€ ë³´ë‚¸ ë©”ì‹œì§€ë¥¼ ì €ì¥Â·ê´€ë¦¬í•©ë‹ˆë‹¤.
4. **Kafka Connect S3 Sink** (ë™ì¼ EC2)
    - EC2ì—ì„œ Kafka Connectë¥¼ ì‹¤í–‰í•˜ê³  S3 Sink ì»¤ë„¥í„°ë¥¼ ì„¤ì •í•©ë‹ˆë‹¤.
    - ì´ ì»¤ë„¥í„°ê°€ clickstream í† í”½ì„ ì†Œë¹„í•´ ì§€ì •ëœ ì£¼ê¸°(Flush size)ë§ˆë‹¤ S3 ë²„í‚·ì— JSON/Parquet íŒŒì¼ë¡œ ë°°ì¹˜ ì ì¬í•©ë‹ˆë‹¤.
5. **Amazon S3**
    - ìµœì¢…ì ìœ¼ë¡œ ì ì¬ëœ ë¡œê·¸ ë°ì´í„°ëŠ” S3 ë²„í‚·ì— ì €ì¥ë˜ì–´, í›„ì† ë¶„ì„ ë° ì‹œê°í™”ì— í™œìš©í•  ì˜ˆì •ì…ë‹ˆë‹¤.

---

## ğŸ¯ ì´ë²ˆ ê¸€ ëª©í‘œ

ë‹¤ìŒê³¼ ê°™ì€ ì•„í‚¤í…ì²˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ì˜¤ëŠ˜ì€ ec2ì— ë„ìš´ ì¹´í”„ì¹´ì˜ ì„¤ì •ì„ ë§ˆì¹˜ê³  lambdaë¥¼ ë°°í¬í•´ì•¼í•©ë‹ˆë‹¤.
1. Lambda Producer ë°°í¬í•˜ê¸°
    - ì»¨í…Œì´ë„ˆ í˜•íƒœë¡œ ë°°í¬í•˜ê¸° (with ECR)
2. S3 ë²„í‚· ìƒì„±í•˜ê¸°
    - ë²„í‚· ìƒì„±ì„ ìœ„í•œ ë°ì´í„° ì €ì¥ ë°©ì‹ ê²°ì •
    - ë²„í‚· ë³´í˜¸ë¥¼ ìœ„í•œ ê·œì¹™ ì„¤ì •
3. EC2 ì¹´í”„ì¹´ ë°°í¬í•˜ê¸°
    - í¼ë¸”ë¦­ ì„œë¸Œë„· EC2ì— ì¹´í”„ì¹´ ì„¤ì •ì„ ëë‚´ê³ 
    - S3 Sink ì»¤ë„¥í„°ë¥¼ ì„¤ì •í•˜ê¸°

---

### 1. Lambda Producer ìƒì„±í•˜ê¸°

ëŒë‹¤ì— kafka í”„ë¡œë“€ì„œ ì½”ë“œë¥¼ ë„ì»¤ ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¡œ ì‘ì„±í•˜ê³  ECRë¡œ ì˜¬ë ¤ë³´ê² ìŠµë‹ˆë‹¤.

#### a. ecrê³¼ lambda ë§Œë“¤ terraform íŒŒì¼ì‘ì„±

ìˆœì„œëŠ” ì´ë ‡ìŠµë‹ˆë‹¤. ë¨¼ì € ecrì„ ë§Œë“¤ê³  ë‚˜ì„œ ê·¸ ì´í›„ì— ecrì— ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ë¥¼ push í•˜ë©´ í•´ë‹¹ ì´ë¯¸ì§€ë¥¼ ëŒë‹¤ë¡œ ì‹¤í–‰í•˜ê²Œ ë©ë‹ˆë‹¤. ê·¸ëŸ¬ê¸° ìœ„í•´ ê°€ì¥ ë¨¼ì € í…Œë¼í¼ íŒŒì¼ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤.

```hcl
# ecr.tf
provider "aws" {
  region = var.region
}

resource "aws_ecr_repository" "kafka_producer" {
  name = "kafka-producer"
  image_scanning_configuration {
    scan_on_push = true
  }
}

# ìˆ˜ëª…ì£¼ê¸° ì •ì±… ì¶”ê°€ (3ê°œ ì´ìƒ ì´ë¯¸ì§€ ìŒ“ì´ë©´ ì œê±°ë¨)
resource "aws_ecr_lifecycle_policy" "kafka_producer_policy" {
  repository = aws_ecr_repository.kafka_producer.name

  policy = <<POLICY
  {
    "rules": [
      {
        "rulePriority": 1,
        "description": "Keep only the most recent 3 images",
        "selection": {
          "tagStatus": "any",
          "countType": "imageCountMoreThan",
          "countNumber": 3
        },
        "action": {
          "type": "expire"
        }
      }
    ]
  }
  POLICY
}
```

ê·¸ë¦¬ê³  ì•„ë˜ì™€ ê°™ì´ 
```hcl
# lambda.tf
... # iam ì„¤ì •

resource "aws_lambda_function" "kafka_producer" {
  function_name = "kafka-producer"
  package_type  = "Image"
  image_uri     = "${aws_ecr_repository.kafka_producer.repository_url}:latest"
  role          = aws_iam_role.lambda_exec.arn
  architectures = ["arm64"]

  environment {
    variables = {
      BOOTSTRAP_SERVERS = "<kafka-server>:9092"
      KAFKA_TOPIC       = "clickstream"
    }
  }
}
```

ë¨¼ì € ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ê°€ ì‚¬ìš©í•  ì•„í‚¤í…ì²˜ë¥¼ arm64ë¡œ ëª…ì‹œí–ˆìŠµë‹ˆë‹¤. ë‹¨ìˆœ ì—°ì‚°ì— ìœ ë¦¬í•˜ê³  ë¬´ì—‡ë³´ë‹¤ m1 ë§¥ë¶ì„ ê°œë°œí•˜ëŠ”ë° ì‚¬ìš©í•˜ê³  ìˆì–´ ë„ì»¤ í…ŒìŠ¤íŠ¸ë‚˜ ì‚¬ìš©ì— ìš©ì´í•©ë‹ˆë‹¤. 
ê·¸ë¦¬ê³  ecrì˜ ì´ë¯¸ì§€ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ì•„ì§ ì´ë¯¸ì§€ê°€ ì˜¬ë¼ê°€ ìˆì§€ ì•Šì•„ `terraform apply`ì‹œ ì—ëŸ¬ê°€ ë°œìƒí•©ë‹ˆë‹¤.

ëŒë‹¤ í™˜ê²½ë³€ìˆ˜ ì¤‘ `BOOTSTRAP_SERVERS`ëŠ” ì¹´í”„ì¹´ ë¶€íŠ¸ìŠ¤íŠ¸ë© ì„œë²„ì˜ ì£¼ì†Œë¥¼ ì…ë ¥í•´ ëŒë‹¤ ì½”ë“œ ë‚´ë¶€ì—ì„œ ì°¸ì¡°í•˜ë„ë¡ í•©ë‹ˆë‹¤.

#### b. Dockerfile ì‘ì„± ë° ì»¨í…Œì´ë„ˆ ì´ë¯¸ì§€ ë¹Œë“œ

ë‹¤ìŒê³¼ ê°™ì´ ë„ì»¤íŒŒì¼ì„ ì‘ì„±í–ˆìŠµë‹ˆë‹¤. ì´ˆê¸°ì—ëŠ” lambda ì´ë¯¸ì§€ë¥¼ ê°€ì ¸ì™€(FROM) ì‚¬ìš©í•˜ê³ ì í–ˆìœ¼ë‚˜ ì¦ì€ ì—ëŸ¬ì™€ ë””ë²„ê¹…ì´ ì–´ë ¤ì›Œ íŒŒì´ì¬ì´ ì‚¬ì „ ì„¤ì¹˜ëœ ë²„ì „ìœ¼ë¡œ ì‚¬ìš©í–ˆìŠµë‹ˆë‹¤.
```dockerfile
# Dockerfile
FROM python:3.9-slim

# 1) ì‹œìŠ¤í…œ íŒ¨í‚¤ì§€
RUN apt-get update && \
    apt-get install -y --no-install-recommends \
      build-essential python3-dev librdkafka-dev ca-certificates \
    && rm -rf /var/lib/apt/lists/*

# 2) RIC(ëŸ°íƒ€ì„ ì¸í„°í˜ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸) + ì•± deps ì„¤ì¹˜
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt awslambdaric

# 3) ì•± ë³µì‚¬
COPY ingest_kafka.py .

# 4) ENTRYPOINT/CMD ì„¤ì •
ENTRYPOINT ["python3", "-m", "awslambdaric"]
CMD ["ingest_kafka.handler"]
```

í•´ë‹¹ ë„ì»¤ì— í¬í•¨ëœ ì•± `ingest_kafka.py`ì€ [ê¸°ì¡´ì— ì‘ì„±í–ˆë˜ fastapi](https://github.com/annmunju/ingest-web-log/blob/main/kafka-ingest/ingest_kafka.py)ì— Mangum ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤. ê´€ë ¨ ì •ë³´ëŠ” [ë¸”ë¡œê·¸](https://yubi5050.tistory.com/257)ë¥¼ ì°¸ê³ í–ˆìŠµë‹ˆë‹¤. 

```bash
# !/bin/bash
AWS_ACCOUNT_ID=$(aws sts get-caller-identity --query Account --output text)
AWS_REGION=$(aws configure get region || echo "ap-northeast-2")
export AWS_ACCOUNT_ID AWS_REGION

docker buildx build \
  --platform linux/arm64 \
  -t kafka-producer:latest \
  --load \
  .

docker tag kafka-producer:latest \
  $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/kafka-producer:latest
```

#### c. terraform ì‹¤í–‰ ë° ecr ì´ë¯¸ì§€ ì—…ë¡œë“œ

ëª¨ë“  ì¤€ë¹„ê°€ ëë‚œ ìƒí™©ì—ì„œ ìˆœì„œì— ë§ê²Œ ecrì„ ìƒì„±í•˜ê³  ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•œ í›„ ëŒë‹¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
```bash
# !/bin/bash
terraform init

# ecr ìƒì„±
terraform apply -target=aws_ecr_repository.kafka_producer

# ecr ë¡œê·¸ì¸
aws ecr get-login-password \
  --region $AWS_REGION \
| docker login \
  --username AWS \
  --password-stdin $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com

# ë ˆì§€ìŠ¤íŠ¸ë¦¬ì— push
docker push $AWS_ACCOUNT_ID.dkr.ecr.$AWS_REGION.amazonaws.com/kafka-producer:latest

# ë‚˜ë¨¸ì§€ ëŒë‹¤ ì ìš©
terraform apply -auto-approve
```

í•´ë‹¹ ì „ì²´ ê³¼ì •ì„ í†µí•´ ëŒë‹¤ê°€ ì •ìƒ ë°°í¬ë©ë‹ˆë‹¤. ì¹´í”„ì¹´ê°€ EC2ì— ì •ìƒì ìœ¼ë¡œ ë„ì›Œì ¸ ìˆì–´ ëŒë‹¤ í…ŒìŠ¤íŠ¸ Jsonì„ ë‹¤ìŒê³¼ ê°™ì´ ì‘ì„±í•˜ê³  ì‹¤í–‰í•˜ë©´ ë°”ë¥´ê²Œ ì „ì†¡ë˜ëŠ” ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

<div style="display: flex; justify-content: center; gap: 2%; align-items: flex-start;">
  <img src="sources/project1_Ingest-web-click-log/2025-05-28-ëŒë‹¤-S3-ì €ì¥/02.png" alt="í…ŒìŠ¤íŠ¸" style="height: auto;">
  <img src="sources/project1_Ingest-web-click-log/2025-05-28-ëŒë‹¤-S3-ì €ì¥/03.png" alt="ê²°ê³¼" style="height: auto;">
</div>

---

### 2. S3 ë²„í‚· ìƒì„±í•˜ê¸°  

#### a. s3 ë²„í‚· ìƒì„±

ì €ëŠ” S3ì˜ ê²½ìš° ì½˜ì†”ì—ì„œ ë²„í‚·ì„ ìƒì„±í–ˆìŠµë‹ˆë‹¤. ì›ë³¸ íŒŒì¼ê³¼ ê°€ê³µ íŒŒì¼ì„ ë³„ë„ë¡œ í•˜ê¸°ìœ„í•´ ë²„í‚·ëª…ì€ `-raw`ë¡œ ëë‚˜ë„ë¡ ì§€ì •í–ˆìŠµë‹ˆë‹¤.

#### b. ë²„í‚·ì— ì €ì¥í•˜ê¸° ìœ„í•œ ê¶Œí•œ & ì—­í•  ë¶€ì—¬
êµ¬ë™ì¤‘ì¸ ì¹´í”„ì¹´ë§Œ í•´ë‹¹ ë²„í‚·ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ì •ì±…ì„ ìƒì„±í•˜ê³  EC2ì— í•´ë‹¹ ì •ì±…ì„ í¬í•¨í•œ ì—­í• ì„ ìƒì„±, í• ë‹¹í•©ë‹ˆë‹¤.

1. ë²„í‚· ì ‘ê·¼ ê¶Œí•œ ì •ì±… ìƒì„±
```json
{
  "Version": "2012-10-17",
  "Statement": [
    {
      "Sid": "AllowS3ListAndGetLocation",
      "Effect": "Allow",
      "Action": [
        "s3:ListBucket",
        "s3:GetBucketLocation"
      ],
      "Resource": "arn:aws:s3:::your-bucket-name"
    },
    {
      "Sid": "AllowS3Writes",
      "Effect": "Allow",
      "Action": [
        "s3:PutObject",
        "s3:AbortMultipartUpload",
        "s3:ListMultipartUploadParts"
      ],
      "Resource": "arn:aws:s3:::your-bucket-name/*"
    }
  ]
}
```

2. ê¶Œí•œì„ ì—­í• ì— í¬í•¨ì‹œí‚¨ í›„ í•´ë‹¹ ì—­í•  EC2ì— ì—°ê²°
ìœ„ì™€ ê°™ì€ ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ” ì •ì±…ì„ ìƒì„±í•´ ì—­í• ì— ë¶™ì—¬ì¤ë‹ˆë‹¤. í•´ë‹¹ ì—­í• ì€ EC2ì— ì—°ê²°í•©ë‹ˆë‹¤.
   <div style="display: flex; justify-content: center; gap: 2%; align-items: flex-start;">
   <img src="sources/project1_Ingest-web-click-log/2025-05-28-ëŒë‹¤-S3-ì €ì¥/04.png" alt="ì—­í•  ìƒì„±" style="height: auto;">
   <img src="sources/project1_Ingest-web-click-log/2025-05-28-ëŒë‹¤-S3-ì €ì¥/05.png" alt="EC2ì— ì—­í•  ì—°ê²°" style="height: auto;">
   </div>

3. ë²„í‚· ì •ì±…ì— Principal ì§€ì •í•´ í•´ë‹¹ ì—­í• ë¡œë§Œ í—ˆìš©í•˜ê²Œ ì„¤ì •
ë²„í‚· ì •ì±…ì„ í†µí•´ EC2 ì—­í• ë§Œ í—ˆìš©í•˜ëŠ” ë¦¬ì†ŒìŠ¤ ê¸°ë°˜ ì ‘ê·¼ í†µì œë¥¼ ì¶”ê°€ë¡œ ê±¸ì–´ ì¤ë‹ˆë‹¤. 

```json
{
    "Version": "2012-10-17",
    "Statement": [
        {
            "Sid": "AllowKafkaConnectRoleListBucket",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::<id>:role/KafkaConnectRole"
            },
            "Action": [
                "s3:ListBucket",
                "s3:GetBucketLocation"
            ],
            "Resource": "arn:aws:s3:::kafka-connect-s3-raw"
        },
        {
            "Sid": "AllowKafkaConnectRoleWrites",
            "Effect": "Allow",
            "Principal": {
                "AWS": "arn:aws:iam::<id>:role/KafkaConnectRole"
            },
            "Action": [
                "s3:PutObject",
                "s3:AbortMultipartUpload",
                "s3:ListMultipartUploadParts"
            ],
            "Resource": "arn:aws:s3:::kafka-connect-s3-raw/*"
        }
    ]
}
```
ìœ„ì™€ ê°™ì€ ì„¤ì •ì„ ë²„í‚· ì •ì±…ì— ì ìš©í•˜ë©´ ì˜ë„ì¹˜ ì•Šì€ ê¶Œí•œ í™•ì¥ì´ë‚˜ ì™¸ë¶€ ì¹¨ì… ì‹œë„ë¥¼ íš¨ê³¼ì ìœ¼ë¡œ ë°©ì–´í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

> ì„¤ì •ì„ ë§ˆì¹˜ë©´ EC2ëŠ” í•´ë‹¹ ë²„í‚·ì— ì ‘ì†í•  ìˆ˜ ìˆê²Œ ë©ë‹ˆë‹¤!

---

### 3. EC2 ì¹´í”„ì¹´ ë°°í¬í•˜ê¸°  

ì§€ë‚œ ê²Œì‹œê¸€ì—ëŠ” ì¹´í”„ì¹´ ë¸Œë¡œì»¤ (ë° ì£¼í”¼ì»¤)ë¥¼ ì‹¤í–‰í–ˆìŠµë‹ˆë‹¤. ì´ë²ˆì—ëŠ” ì»¤ë„¥í„°ë¥¼ ì¶”ê°€í•´ì„œ ì´ ì»¤ë„¥í„°ë¥¼ ë¸Œë¡œì»¤ì— ì—°ê²°í•´ ê¸°ë¡ì„ ì½ê³  S3 Sinkë¡œ ë°ì´í„°ë¥¼ ì „ì†¡í•˜ëŠ” ì „ì²´ ê³¼ì •ì„ ë‹¤ë¤„ë³´ê² ìŠµë‹ˆë‹¤.

#### a. EC2ì—ì„œ Kafka ì„¤ì • ë§ˆë¬´ë¦¬  
ê¸°ì¡´ì— ë“±ë¡í•œ systemdë¥¼ í™œìš©í•´ ë„ì›Œë‘” kafka ë¸Œë¡œì»¤ê°€ ì •ìƒ ì‘ë™ë˜ëŠ”ì§€ í™•ì¸í•©ë‹ˆë‹¤.
```shell
$ sudo systemctl status kafka.service
   Loaded: loaded (/etc/systemd/system/kafka.service; enabled; vendor preset: disabled)
   Active: active (running) since ëª© 2025-05-29 08:51:05 UTC; 28min ago
 Main PID: 24437 (java)
   CGroup: /system.slice/kafka.service
```

ê·¸ë¦¬ê³  í† í”½ì„ ì¶œë ¥í•´ë´…ë‹ˆë‹¤.
```shell
$ /opt/confluent/bin/kafka-topics --bootstrap-server localhost:9092 --list
   clickstream

$ # í† í”½ ì •ë³´ ì¶œë ¥
$ /opt/confluent/bin/kafka-topics --bootstrap-server localhost:9092 --describe --topic clickstream
   Topic: clickstream	TopicId: 8-L3WOkyRoWmHGZcfZRLUw	PartitionCount: 1	ReplicationFactor: 1	Configs:
	Topic: clickstream	Partition: 0	Leader: 0	Replicas: 0	Isr: 0
```

#### b. Kafka Connect S3 Sink ì»¤ë„¥í„° ì„¤ì •í•˜ê¸°

ìš°ì„  ì €ëŠ” [Confluent Hubì˜ Amazon S3 Sink Connector](https://www.confluent.io/hub/confluentinc/kafka-connect-s3)ì„ ì§ì ‘ ì„œë²„ì— ì„¤ì¹˜í–ˆìŠµë‹ˆë‹¤. Confluent Platform â€“ self-managed í˜•ì‹ìœ¼ë¡œ ZIP íŒŒì¼ì„ ë‹¤ìš´ë¡œë“œë°›ì•„ ì¹´í”„ì¹´ EC2 ì„œë²„ì— ì „ì†¡í•œ ë’¤, ì•„ë˜ ìˆœì„œëŒ€ë¡œ ì„¤ì •ì„ ë§ˆë¬´ë¦¬í–ˆìŠµë‹ˆë‹¤.

1. í”ŒëŸ¬ê·¸ì¸ ì••ì¶• í•´ì œ ë° ë””ë ‰í„°ë¦¬ ì´ë™  
```bash
# ì„œë²„ë¡œ ZIP íŒŒì¼ ì „ì†¡ í›„
unzip confluentinc-kafka-connect-s3-10.6.5.zip -d /opt/kafka/plugins/
```

2.	standalone ì„¤ì • íŒŒì¼ì— plugin.path ì¶”ê°€
```bash
# /opt/confluent/etc/kafka/connect-standalone.properties
# (ê¸°ì¡´ í•­ëª©ì— ì¶”ê°€)
plugin.path=/opt/kafka/plugins/confluentinc-kafka-connect-s3-10.6.5
```

3.	quickstart-s3 ì„¤ì • íŒŒì¼ ë³µì‚¬
```bash
cp /opt/kafka/plugins/confluentinc-kafka-connect-s3-10.6.5/etc/quickstart-s3.properties /opt/confluent/etc/kafka/quickstart-s3.properties
```

4. íŒŒì¼ êµ¬ì„± ìš”ì†Œ ìˆ˜ì •
   ```ini
   name=s3-sink
   connector.class=io.confluent.connect.s3.S3SinkConnector
   tasks.max=1
   topics=clickstream

   s3.region=ap-northeast-2
   s3.bucket.name=<ë²„í‚· ì´ë¦„>
   s3.part.size=67108864
   flush.size=1000

   storage.class=io.confluent.connect.s3.storage.S3Storage
   format.class=io.confluent.connect.s3.format.avro.AvroFormat
   partitioner.class=io.confluent.connect.storage.partitioner.TimeBasedPartitioner

   schema.compatibility=NONE
   partition.duration.ms=3600000
   path.format='year=!{timestamp:yyyy}/month=!{timestamp:MM}/day=!{timestamp:dd}/hour=!{timestamp:HH}'
   locale=ko_KR
   timezone=Asia/Seoul
   ```

5.	systemd ì„œë¹„ìŠ¤ ìœ ë‹› íŒŒì¼ ìƒì„±

```ini
[Unit]
Description=Kafka Connect Standalone (S3 Sink)
After=network.target

[Service]
Type=simple
User=ec2-user
ExecStart=/opt/confluent/bin/connect-standalone \
/opt/confluent/etc/kafka/connect-standalone.properties \
/opt/confluent/etc/kafka/quickstart-s3.properties
Restart=on-failure
RestartSec=10
LimitNOFILE=65536

[Install]
WantedBy=multi-user.target
```

- ì´ì œ ë‹¤ìŒì„ ì‹¤í–‰í•˜ë©´ systemd ë°ëª¬ì´ ë‹¤ì‹œ ì‹¤í–‰ë˜ê³  ì„œë¹„ìŠ¤ê°€ í™œì„±í™” ë©ë‹ˆë‹¤.

```bash
$ sudo systemctl daemon-reload
$ sudo systemctl enable kafka-connect.service
$ sudo systemctl start kafka-connect.service

$ # ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
$ sudo systemctl status kafka-connect.service
   Loaded: loaded (/etc/systemd/system/kafka-connect.service; enabled; vendor preset: disabled)
   Active: active (running) since ëª© 2025-05-29 08:54:45 UTC; 44min ago
Main PID: 28748 (java)
   CGroup: /system.slice/kafka-connect.service
```

---

## ğŸš€ ê²°ë¡  ë° ì´í›„ ê³„íš

ì´ë²ˆ ê¸€ì—ì„œëŠ”  
- **ì»¨í…Œì´ë„ˆ Lambda Producer**ë¥¼ ECR + Terraformìœ¼ë¡œ ë°°í¬í•˜ê³ ,  
- **S3 ë²„í‚·**ì„ raw ë°ì´í„°ìš©ìœ¼ë¡œ ìƒì„±Â·ê¶Œí•œ ì„¤ì •í•˜ë©°,  
- **Kafka Connect S3 Sink** ì»¤ë„¥í„°ë¥¼ systemd ì„œë¹„ìŠ¤ë¡œ ìë™í™”í•´ `clickstream` í† í”½ì„ `year=/month=/day=/hour=` êµ¬ì¡°ë¡œ S3ì— ë°°ì¹˜ ì ì¬  

ê¹Œì§€ end-to-end íŒŒì´í”„ë¼ì¸ì„ ì™„ì„±í–ˆìŠµë‹ˆë‹¤. ì¬ë¶€íŒ… í›„ì—ë„ systemdê°€ ìë™ ê¸°ë™í•©ë‹ˆë‹¤. ë‹¤ìŒì€ S3 ì—…ë¡œë“œë¥¼ ê²€ì¦í•˜ê³  í•´ë‹¹ ë°ì´í„°ë¥¼ HDFSì— íŒŒì¼ë¡œ ì €ì¥í•˜ê³  ë°°ì¹˜ ë¶„ì„ì„ ì‹¤í–‰í•˜ëŠ” ë‹¨ê³„ë¥¼ ì´ì–´ê°€ê² ìŠµë‹ˆë‹¤.

--- 

## ì°¸ê³  ìë£Œ
- [Amazon S3 Sink Connector for Confluent Platform](https://docs.confluent.io/kafka-connectors/s3-sink/current/overview.html)
- [Deploy Python Lambda functions with container images](https://docs.aws.amazon.com/lambda/latest/dg/python-image.html)
- [Examples of lifecycle policies in Amazon ECR](https://docs.aws.amazon.com/AmazonECR/latest/userguide/lifecycle_policy_examples.html)
- [AWS Lambda Terraform module
](https://github.com/terraform-aws-modules/terraform-aws-lambda)